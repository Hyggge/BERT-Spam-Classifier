{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:29.972851Z","iopub.status.busy":"2023-12-02T02:59:29.972165Z","iopub.status.idle":"2023-12-02T02:59:29.982315Z","shell.execute_reply":"2023-12-02T02:59:29.980981Z","shell.execute_reply.started":"2023-12-02T02:59:29.972813Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import os\n","import numpy as np\n","import pandas as pd\n","import transformers\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:29.984903Z","iopub.status.busy":"2023-12-02T02:59:29.984507Z","iopub.status.idle":"2023-12-02T02:59:29.993518Z","shell.execute_reply":"2023-12-02T02:59:29.992647Z","shell.execute_reply.started":"2023-12-02T02:59:29.984871Z"},"trusted":true},"outputs":[],"source":["# prexy setting\n","# os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n","# os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:29.995218Z","iopub.status.busy":"2023-12-02T02:59:29.994725Z","iopub.status.idle":"2023-12-02T02:59:31.245351Z","shell.execute_reply":"2023-12-02T02:59:31.244390Z","shell.execute_reply.started":"2023-12-02T02:59:29.995194Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((3537, 6), (2035, 6))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv(\"./train.csv\")\n","test_data = pd.read_csv(\"./test.csv\")\n","train_data.v1 = train_data.v1.replace({\"ham\": 0, \"spam\": 1})\n","test_data.v1 = test_data.v1.replace({\"ham\": 0, \"spam\": 1})\n","train_data.shape, test_data.shape\n"]},{"cell_type":"markdown","metadata":{},"source":["### 构造 DataSet 和 DataLoader"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:31.247140Z","iopub.status.busy":"2023-12-02T02:59:31.246738Z","iopub.status.idle":"2023-12-02T02:59:31.256014Z","shell.execute_reply":"2023-12-02T02:59:31.254979Z","shell.execute_reply.started":"2023-12-02T02:59:31.247109Z"},"trusted":true},"outputs":[],"source":["class SMSDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length):\n","        super(SMSDataset, self).__init__()\n","        self.tokenizer=tokenizer\n","        self.max_length=max_length\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","        \n","        text= self.data.iloc[index, 2]\n","        \n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            padding='max_length',\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            truncation=True,\n","            max_length=self.max_length,\n","        )\n","\n","        ids = inputs[\"input_ids\"]\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'target': torch.tensor(self.data.iloc[index, 1], dtype=torch.long)\n","        }\n"]},{"cell_type":"markdown","metadata":{},"source":["### 创建模型"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:31.258900Z","iopub.status.busy":"2023-12-02T02:59:31.258588Z","iopub.status.idle":"2023-12-02T02:59:31.270203Z","shell.execute_reply":"2023-12-02T02:59:31.269379Z","shell.execute_reply.started":"2023-12-02T02:59:31.258876Z"},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n","        self.head = nn.Sequential(\n","            nn.Linear(768, 768),\n","            nn.ReLU(),\n","            nn.Linear(768, 768),\n","            nn.ReLU(),\n","            # nn.Dropout(0.5),\n","            nn.Linear(768, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        _, o2= self.bert(\n","            ids, \n","            attention_mask=mask,\n","            token_type_ids=token_type_ids,\n","            return_dict=False\n","        )\n","        out= self.head(o2)\n","        return out\n"]},{"cell_type":"markdown","metadata":{},"source":["### 训练"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:31.272225Z","iopub.status.busy":"2023-12-02T02:59:31.271438Z","iopub.status.idle":"2023-12-02T02:59:31.280128Z","shell.execute_reply":"2023-12-02T02:59:31.279331Z","shell.execute_reply.started":"2023-12-02T02:59:31.272179Z"},"trusted":true},"outputs":[],"source":["# hyper-parameters\n","num_epochs = 20\n","lr = 0.0001 # op = 0.0001\n","# weight_decay = 0.005\n","batch_size = 64\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:31.281567Z","iopub.status.busy":"2023-12-02T02:59:31.281268Z","iopub.status.idle":"2023-12-02T02:59:39.150165Z","shell.execute_reply":"2023-12-02T02:59:39.149219Z","shell.execute_reply.started":"2023-12-02T02:59:31.281543Z"},"trusted":true},"outputs":[],"source":["tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","train_dataset = SMSDataset(train_data, tokenizer, max_length=100)\n","test_dataset = SMSDataset(test_data, tokenizer, max_length=100)\n","model = Classifier()\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:39.152301Z","iopub.status.busy":"2023-12-02T02:59:39.151433Z","iopub.status.idle":"2023-12-02T02:59:39.168607Z","shell.execute_reply":"2023-12-02T02:59:39.167735Z","shell.execute_reply.started":"2023-12-02T02:59:39.152272Z"},"trusted":true},"outputs":[],"source":["# frozen bert\n","# for param in model.bert.parameters():\n","#     param.requires_grad = False\n","\n","# init_weights\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        nn.init.xavier_uniform_(m.weight)\n","        nn.init.zeros_(m.bias)\n","\n","model.head.apply(init_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:39.170604Z","iopub.status.busy":"2023-12-02T02:59:39.170088Z","iopub.status.idle":"2023-12-02T02:59:39.190787Z","shell.execute_reply":"2023-12-02T02:59:39.189846Z","shell.execute_reply.started":"2023-12-02T02:59:39.170570Z"},"trusted":true},"outputs":[],"source":["def eval(model, dataloader, loss_fn, return_pred=False):\n","    # set model to eval mode\n","    model.eval()\n","    \n","    # init\n","    sample_num = 0\n","    test_loss_total = 0\n","    test_correct_pred_total = 0\n","    pred_list = [] if return_pred else None\n","\n","    # start evalation\n","    with torch.no_grad():\n","        loop= tqdm(enumerate(dataloader), leave=False, total=len(dataloader))\n","        for batch, inputs in loop:\n","            ids, token_type_ids, mask = inputs['ids'], inputs['token_type_ids'], inputs['mask']\n","            label = inputs['target'].unsqueeze(1)\n","\n","            # forward\n","            output = model(\n","                ids=ids.to(device),\n","                mask=mask.to(device),\n","                token_type_ids=token_type_ids.to(device)\n","            )\n","            \n","            # update total number\n","            sample_num += ids.shape[0]\n","\n","            # update test_loss_total \n","            label = label.type_as(output)\n","            loss = loss_fn(output, label)\n","            test_loss_total += loss.item()\n","\n","            # update test_correct_pred_total\n","            pred = torch.round(output)\n","            test_correct_pred_total += (pred == label).sum().item()\n","\n","            # if return_pred is True, add pred to pred_list\n","            if return_pred:\n","                pred_list.append(pred.reshape(-1))\n","            \n","            # Show progress while training\n","            loop.set_description(f'Evalating ...')\n","    \n","    pred_list = torch.cat(pred_list) if return_pred else None\n","    test_accuracy_total = test_correct_pred_total / sample_num\n","    \n","    print(sample_num)\n","    return pred_list, test_loss_total, test_accuracy_total\n","\n","\n","def train(model, dataloader, loss_fn, optimizer, epoch):\n","    # set model to train mode\n","    model.train()\n","    \n","    # init\n","    sample_num = 0\n","    train_loss_total = 0\n","    train_correct_pred_total = 0\n","\n","    # start training\n","    loop = tqdm(enumerate(dataloader), leave=False, total=len(dataloader))\n","    for batch, inputs in loop:\n","        # get input data\n","        ids, token_type_ids, mask = inputs['ids'], inputs['token_type_ids'], inputs['mask']\n","        label = inputs['target'].unsqueeze(1)\n","        \n","        # forward\n","        output = model(\n","            ids=ids.to(device),\n","            mask=mask.to(device),\n","            token_type_ids=token_type_ids.to(device)\n","        )\n","\n","        # backward\n","        label = label.type_as(output)\n","        optimizer.zero_grad()\n","        loss = loss_fn(output, label)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # calculate accuracy\n","        pred = torch.round(output)\n","        num_correct = (pred == label).sum().item()\n","        num_samples = label.shape[0]\n","        accuracy = num_correct / num_samples\n","\n","        # update total number, train_loss_total and train_correct_pred_total\n","        sample_num += ids.shape[0]\n","        train_loss_total += loss.item()\n","        train_correct_pred_total += num_correct\n","        \n","        # Show progress while training\n","        loop.set_description(f'Epoch {epoch+1}, batch {batch} / {len(dataloader)}')\n","        loop.set_postfix(loss=loss.item(), acc=accuracy)\n","\n","    print(sample_num)\n","    train_accuracy_total = train_correct_pred_total / sample_num\n","    return train_loss_total, train_accuracy_total\n","\n","\n","def train_and_eval(model, train_dataset, test_dataset, num_epochs, lr, batch_size):\n","    # dataloader\n","    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n","    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n","    # loss\n","    loss_fn = nn.BCELoss()\n","    # optimizer\n","    optimizer= optim.AdamW(model.parameters(), lr=lr)\n","    # move model to device\n","    model.to(device)\n","    \n","    for epoch in range(num_epochs):\n","        # training\n","        train_loss_total, train_accuracy_total = train(model, train_dataloader, loss_fn, optimizer, epoch)\n","        # evalation\n","        _, test_loss_total, test_accuracy_total = eval(model, test_dataloader, loss_fn)\n","        \n","        \n","        print(f\"Epoch {epoch + 1} end.\")\n","        print(f\"Train loss: {train_loss_total}, Train accuracy: {train_accuracy_total}\")\n","        print(f\"Test loss: {test_loss_total}, Test accuracy: {test_accuracy_total}\")\n","                \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:39.192272Z","iopub.status.busy":"2023-12-02T02:59:39.191994Z","iopub.status.idle":"2023-12-02T02:59:39.207010Z","shell.execute_reply":"2023-12-02T02:59:39.206047Z","shell.execute_reply.started":"2023-12-02T02:59:39.192250Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Classifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (head): Sequential(\n","    (0): Linear(in_features=768, out_features=768, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=768, out_features=768, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=768, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T02:59:39.208549Z","iopub.status.busy":"2023-12-02T02:59:39.208157Z"},"trusted":true},"outputs":[],"source":["train_and_eval(model, train_dataset, test_dataset, num_epochs, lr, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n","loss_fn = nn.BCELoss()\n","pred, test_loss_total, test_accuracy_total = eval(model, test_dataloader, loss_fn, True)\n","print(test_accuracy_total)\n","\n","with open(\"submission.txt\", \"w\") as f:\n","    for i in pred.cpu().detach().numpy():\n","        if (i == 0.0):\n","            f.write(\"ham\\n\")\n","        else:\n","            f.write(\"spam\\n\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4073216,"sourceId":7075717,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
