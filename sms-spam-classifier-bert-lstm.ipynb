{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:02.641423Z","iopub.status.busy":"2023-12-09T13:17:02.640652Z","iopub.status.idle":"2023-12-09T13:17:05.912617Z","shell.execute_reply":"2023-12-09T13:17:05.911647Z","shell.execute_reply.started":"2023-12-09T13:17:02.641382Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import os\n","import numpy as np\n","import pandas as pd\n","import transformers\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:05.914528Z","iopub.status.busy":"2023-12-09T13:17:05.914153Z","iopub.status.idle":"2023-12-09T13:17:05.918639Z","shell.execute_reply":"2023-12-09T13:17:05.917489Z","shell.execute_reply.started":"2023-12-09T13:17:05.914502Z"},"trusted":true},"outputs":[],"source":["# os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n","# os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:22:26.608680Z","iopub.status.busy":"2023-12-09T13:22:26.608032Z","iopub.status.idle":"2023-12-09T13:22:26.649439Z","shell.execute_reply":"2023-12-09T13:22:26.648483Z","shell.execute_reply.started":"2023-12-09T13:22:26.608646Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"./train.csv\")\n","test_data = pd.read_csv(\"./test.csv\")\n","shuffled_indices = np.random.permutation(len(train_data))\n","split_point = int(0.8 * len(train_data))\n","train_data, valid_data = \\\n","    train_data.iloc[shuffled_indices[:split_point]], \\\n","    train_data.iloc[shuffled_indices[split_point:]]\n","\n","\n","train_data.v1 = train_data.v1.replace({\"ham\": 0, \"spam\": 1})\n","test_data.v1 = test_data.v1.replace({\"ham\": 0, \"spam\": 1})\n","valid_data.v1 = valid_data.v1.replace({\"ham\": 0, \"spam\": 1})\n","\n","train_data.shape, valid_data.shape, test_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["### 构造 DataSet 和 DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:06.018819Z","iopub.status.busy":"2023-12-09T13:17:06.018516Z","iopub.status.idle":"2023-12-09T13:17:06.027059Z","shell.execute_reply":"2023-12-09T13:17:06.026350Z","shell.execute_reply.started":"2023-12-09T13:17:06.018773Z"},"trusted":true},"outputs":[],"source":["class SMSDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length):\n","        super(SMSDataset, self).__init__()\n","        self.tokenizer=tokenizer\n","        self.max_length=max_length\n","        self.data = data\n","\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","        \n","        text= self.data.iloc[index, 2]\n","        \n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            padding='max_length',\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            truncation=True,\n","            max_length=self.max_length,\n","        )\n","\n","        \n","        ids = inputs[\"input_ids\"]\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'target': torch.tensor(self.data.iloc[index, 1], dtype=torch.long)\n","        }\n","    "]},{"cell_type":"markdown","metadata":{},"source":["### 创建模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:06.028528Z","iopub.status.busy":"2023-12-09T13:17:06.028147Z","iopub.status.idle":"2023-12-09T13:17:06.042304Z","shell.execute_reply":"2023-12-09T13:17:06.041395Z","shell.execute_reply.started":"2023-12-09T13:17:06.028483Z"},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n","        self.hidden_size = self.bert.config.hidden_size\n","        self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size, bidirectional=True)\n","        self.head = nn.Sequential(\n","            nn.Linear(self.hidden_size * 2, self.hidden_size),\n","            nn.ReLU(), nn.Dropout(0.5),\n","            nn.Linear(self.hidden_size, self.hidden_size),\n","            nn.ReLU(), nn.Dropout(0.5),\n","            nn.Linear(self.hidden_size, 1),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, ids, mask, token_type_ids):\n","        encoded_layers, pooled_output = self.bert(\n","            ids, \n","            attention_mask=mask,\n","            token_type_ids=token_type_ids,\n","            return_dict=False\n","        )\n","        encoded_layers = encoded_layers.permute(1, 0, 2)\n","        all_hiddens, (last_hidden, last_cell) = self.LSTM(\n","            pack_padded_sequence(\n","                encoded_layers, \n","                torch.sum(mask, dim = -1).to(torch.device(\"cpu\")),\n","                enforce_sorted=False\n","            )\n","        )\n","        out = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n","        out = F.dropout(out, 0.5)\n","        out = self.head(out)\n","        return out\n"]},{"cell_type":"markdown","metadata":{},"source":["### 训练"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:06.043508Z","iopub.status.busy":"2023-12-09T13:17:06.043251Z","iopub.status.idle":"2023-12-09T13:17:06.055555Z","shell.execute_reply":"2023-12-09T13:17:06.054855Z","shell.execute_reply.started":"2023-12-09T13:17:06.043485Z"},"trusted":true},"outputs":[],"source":["# hyper-parameters\n","num_epochs = 10\n","lr = 0.00001 # op = 0.0001\n","# weight_decay = 0.005\n","batch_size = 64\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:06.057127Z","iopub.status.busy":"2023-12-09T13:17:06.056644Z","iopub.status.idle":"2023-12-09T13:17:11.076951Z","shell.execute_reply":"2023-12-09T13:17:11.076054Z","shell.execute_reply.started":"2023-12-09T13:17:06.057096Z"},"trusted":true},"outputs":[],"source":["tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","train_dataset = SMSDataset(train_data, tokenizer, max_length=100)\n","test_dataset = SMSDataset(test_data, tokenizer, max_length=100)\n","valid_dataset = SMSDataset(valid_data, tokenizer, max_length=100)\n","model = Classifier()\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:11.079234Z","iopub.status.busy":"2023-12-09T13:17:11.078327Z","iopub.status.idle":"2023-12-09T13:17:11.098344Z","shell.execute_reply":"2023-12-09T13:17:11.097473Z","shell.execute_reply.started":"2023-12-09T13:17:11.079194Z"},"trusted":true},"outputs":[],"source":["# frozen bert\n","# for param in model.bert.parameters():\n","#     param.requires_grad = False\n","\n","# init_weights\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        nn.init.xavier_uniform_(m.weight)\n","        nn.init.zeros_(m.bias)\n","\n","model.head.apply(init_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:11.100211Z","iopub.status.busy":"2023-12-09T13:17:11.099946Z","iopub.status.idle":"2023-12-09T13:17:11.118134Z","shell.execute_reply":"2023-12-09T13:17:11.117246Z","shell.execute_reply.started":"2023-12-09T13:17:11.100187Z"},"trusted":true},"outputs":[],"source":["def eval(model, dataloader, loss_fn, return_pred=False):\n","    # set model to eval mode\n","    model.eval()\n","    \n","    # init\n","    test_loss_total = 0\n","    test_correct_pred_total = 0\n","    pred_list = [] if return_pred else None\n","\n","    # start evalation\n","    with torch.no_grad():\n","        loop= tqdm(enumerate(dataloader), leave=False, total=len(dataloader))\n","        for batch, inputs in loop:\n","            ids, token_type_ids, mask = inputs['ids'], inputs['token_type_ids'], inputs['mask']\n","            label = inputs['target'].unsqueeze(1)\n","\n","            # forward\n","            output = model(\n","                ids=ids.to(device),\n","                mask=mask.to(device),\n","                token_type_ids=token_type_ids.to(device)\n","            )\n","\n","            # update test_loss_total \n","            label = label.type_as(output)\n","            loss = loss_fn(output, label)\n","            test_loss_total += loss.item()\n","\n","            # update test_correct_pred_total\n","            pred = torch.round(output)\n","            test_correct_pred_total += (pred == label).sum().item()\n","\n","            # if return_pred is True, add pred to pred_list\n","            if return_pred:\n","                pred_list.append(pred.reshape(-1))\n","            \n","            # Show progress while training\n","            loop.set_description(f'Evalating ...')\n","    \n","    pred_list = torch.cat(pred_list) if return_pred else None\n","    test_accuracy_total = test_correct_pred_total / len(test_dataset)\n","\n","    return pred_list, test_loss_total, test_accuracy_total\n","\n","\n","def train(model, dataloader, loss_fn, optimizer, epoch):\n","    # set model to train mode\n","    model.train()\n","    \n","    # init\n","    train_loss_total = 0\n","    train_correct_pred_total = 0\n","\n","    # start training\n","    loop = tqdm(enumerate(dataloader), leave=False, total=len(dataloader))\n","    for batch, inputs in loop:\n","        # get input data\n","        ids, token_type_ids, mask = inputs['ids'], inputs['token_type_ids'], inputs['mask']\n","        label = inputs['target'].unsqueeze(1)\n","        \n","        # forward\n","        output = model(\n","            ids=ids.to(device),\n","            mask=mask.to(device),\n","            token_type_ids=token_type_ids.to(device)\n","        )\n","\n","        # backward\n","        label = label.type_as(output)\n","        optimizer.zero_grad()\n","        loss = loss_fn(output, label)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # calculate accuracy\n","        pred = torch.round(output)\n","        num_correct = (pred == label).sum().item()\n","        num_samples = label.shape[0]\n","        accuracy = num_correct / num_samples\n","\n","        # update train_loss_total and train_correct_pred_total\n","        train_loss_total += loss.item()\n","        train_correct_pred_total += num_correct\n","        \n","        # Show progress while training\n","        loop.set_description(f'Epoch {epoch}, batch {batch} / {len(dataloader)}')\n","        loop.set_postfix(loss=loss.item(), acc=accuracy)\n","\n","    train_accuracy_total = train_correct_pred_total / len(train_dataset)\n","    return train_loss_total, train_accuracy_total\n","\n","\n","def train_and_eval(model, train_dataset, valid_dataset, test_dataset, num_epochs, lr, batch_size):\n","    # dataloader\n","    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n","    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n","    # loss\n","    loss_fn = nn.BCELoss()\n","    # optimizer\n","    optimizer= optim.Adam(model.parameters(), lr=lr)\n","    # move model to device\n","    model.to(device)\n","    \n","    for epoch in range(num_epochs):\n","        # training\n","        train_loss_total, train_accuracy_total = train(model, train_dataloader, loss_fn, optimizer, epoch)\n","        # evalation\n","        _, test_loss_total, test_accuracy_total = eval(model, test_dataloader, loss_fn)\n","        \n","        print(f\"Epoch {epoch + 1} end.\")\n","        print(f\"Train loss: {train_loss_total}, Train accuracy: {train_accuracy_total}\")\n","        print(f\"Test loss: {test_loss_total}, Test accuracy: {test_accuracy_total}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:11.121200Z","iopub.status.busy":"2023-12-09T13:17:11.120921Z","iopub.status.idle":"2023-12-09T13:17:11.134606Z","shell.execute_reply":"2023-12-09T13:17:11.133778Z","shell.execute_reply.started":"2023-12-09T13:17:11.121175Z"},"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T13:17:11.136518Z","iopub.status.busy":"2023-12-09T13:17:11.135654Z","iopub.status.idle":"2023-12-09T13:21:48.616115Z","shell.execute_reply":"2023-12-09T13:21:48.614985Z","shell.execute_reply.started":"2023-12-09T13:17:11.136493Z"},"trusted":true},"outputs":[],"source":["train_and_eval(model, train_dataset, valid_dataset, test_dataset, num_epochs, lr, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-09T13:21:48.616985Z","iopub.status.idle":"2023-12-09T13:21:48.617296Z","shell.execute_reply":"2023-12-09T13:21:48.617155Z","shell.execute_reply.started":"2023-12-09T13:21:48.617140Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"model.pth\")\n","\n","from IPython.display import FileLink\n","os.chdir('/kaggle/working')\n","print(os.getcwd())\n","print(os.listdir(\"/kaggle/working\"))\n","FileLink('model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-09T13:21:48.618141Z","iopub.status.idle":"2023-12-09T13:21:48.618445Z","shell.execute_reply":"2023-12-09T13:21:48.618306Z","shell.execute_reply.started":"2023-12-09T13:21:48.618292Z"},"trusted":true},"outputs":[],"source":["test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n","loss_fn = nn.BCELoss()\n","pred, test_loss_total, test_accuracy_total = eval(model, test_dataloader, loss_fn, True)\n","print(test_accuracy_total)\n","\n","with open(\"submission.txt\", \"w\") as f:\n","    for i in pred.cpu().detach().numpy():\n","    #     print(i)\n","        if (i == 0.0):\n","            f.write(\"ham\\n\")\n","        else:\n","            f.write(\"spam\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-09T13:21:48.619488Z","iopub.status.idle":"2023-12-09T13:21:48.619814Z","shell.execute_reply":"2023-12-09T13:21:48.619661Z","shell.execute_reply.started":"2023-12-09T13:21:48.619646Z"},"trusted":true},"outputs":[],"source":["def torch_gc():\n","    if torch.cuda.is_available():\n","        with torch.cuda.device('cuda:1'):\n","            torch.cuda.empty_cache()\n","            torch.cuda.ipc_collect()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4073216,"sourceId":7075717,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
